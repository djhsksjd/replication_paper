import pandas as pd
import numpy as np
import os
import random
from collections import defaultdict
from typing import Dict, List, Tuple, Optional
import time
import pickle 
from datetime import datetime, timedelta


# ----------------------
# 1. æ¢å¤æ•°æ®ç”Ÿæˆå™¨ï¼ˆè§£å†³æ•°æ®ç¼ºå¤±é—®é¢˜ï¼‰
# ----------------------
class DataGenerator:
    def __init__(self, data_dir: str, num_users: int = 50, num_items: int = 30, 
                 interactions_per_user: tuple = (3, 10), num_categories: int = 5):
        self.data_dir = data_dir
        self.num_users = num_users
        self.num_items = num_items
        self.interactions_per_user = interactions_per_user
        self.num_categories = num_categories
        
        os.makedirs(data_dir, exist_ok=True)
        self.user_ids = [1000 + i for i in range(num_users)]
        self.item_ids = [2000 + i for i in range(num_items)]
        
        self.categories = ["ç”µå­äº§å“", "å®¶å±…ç”¨å“", "æœè£…é…é¥°", "é£Ÿå“é¥®æ–™", "å›¾ä¹¦æ–‡å…·"]
        self.item_type_templates = {
            "ç”µå­äº§å“": ["æ™ºèƒ½æ‰‹è¡¨", "æ— çº¿è€³æœº", "å¹³æ¿ç”µè„‘", "è“ç‰™éŸ³ç®±", "ç§»åŠ¨ç”µæº"],
            "å®¶å±…ç”¨å“": ["ä¿æ¸©æ¯", "æŠ±æ•", "æ”¶çº³ç›’", "å°ç¯", "é¦™è–°èœ¡çƒ›"],
            "æœè£…é…é¥°": ["å›´å·¾", "å¸½å­", "å¢¨é•œ", "æ‰‹é“¾", "é’±åŒ…"],
            "é£Ÿå“é¥®æ–™": ["å·§å…‹åŠ›", "èŒ¶å¶", "å’–å•¡", "åšæœç¤¼ç›’", "æœå¹²"],
            "å›¾ä¹¦æ–‡å…·": ["ç¬”è®°æœ¬", "é’¢ç¬”", "å°è¯´", "å·¥å…·ä¹¦", "åˆ›æ„æ–‡å…·"]
        }
        
        self.interaction_types = ["ç‚¹å‡»", "æ”¶è—", "åŠ å…¥è´­ç‰©è½¦", "è´­ä¹°"]
        self.start_date = datetime(2025, 9, 1)
        self.end_date = datetime(2025, 9, 30)
    
    def generate_user_data(self) -> pd.DataFrame:
        users = pd.DataFrame({
            'user_id': self.user_ids,
            'age': np.random.randint(18, 65, size=self.num_users),
            'gender': np.random.choice(['ç”·', 'å¥³'], size=self.num_users, p=[0.55, 0.45])
        })
        return users
    
    def generate_item_data(self) -> pd.DataFrame:
        item_categories = np.random.choice(self.categories[:self.num_categories], size=self.num_items)
        item_names = []
        for category in item_categories:
            item_type = random.choice(self.item_type_templates[category])
            adjectives = ["é«˜çº§", "æ™ºèƒ½", "æ—¶å°š", "ç»å…¸", "è¿·ä½ ", "ä¾¿æº", "å¤šåŠŸèƒ½", "é«˜å“è´¨"]
            adj = random.choice(adjectives)
            item_names.append(f"{adj}{item_type}")
        
        items = pd.DataFrame({
            'item_id': self.item_ids,
            'item_name': item_names,
            'category': item_categories,
            'price': np.round(np.random.uniform(10, 1000, size=self.num_items), 2)
        })
        return items
    
    def generate_interaction_data(self, users: pd.DataFrame, items: pd.DataFrame) -> pd.DataFrame:
        interactions = []
        for user_id in self.user_ids:
            num_interactions = random.randint(self.interactions_per_user[0], self.interactions_per_user[1])
            user_gender = users.loc[users['user_id'] == user_id, 'gender'].iloc[0]
            category_weights = np.ones(len(self.categories))
            
            if user_gender == 'ç”·':
                category_weights[self.categories.index("ç”µå­äº§å“")] *= 1.5
                category_weights[self.categories.index("å›¾ä¹¦æ–‡å…·")] *= 1.2
            else:
                category_weights[self.categories.index("æœè£…é…é¥°")] *= 1.5
                category_weights[self.categories.index("å®¶å±…ç”¨å“")] *= 1.2
            
            category_weights = category_weights / category_weights.sum()
            interacted_items = set()
            
            while len(interacted_items) < num_interactions:
                preferred_category = np.random.choice(self.categories[:self.num_categories], p=category_weights)
                category_items = items[items['category'] == preferred_category]['item_id'].tolist()
                
                if category_items:
                    item_id = random.choice(category_items)
                    if item_id not in interacted_items:
                        interacted_items.add(item_id)
                        interaction_type = random.choices(
                            self.interaction_types,
                            weights=[0.4, 0.2, 0.2, 0.2],
                            k=1
                        )[0]
                        delta_days = random.randint(0, (self.end_date - self.start_date).days)
                        interaction_time = (self.start_date + timedelta(days=delta_days)).strftime('%Y-%m-%d')
                        interactions.append({
                            'user_id': user_id,
                            'item_id': item_id,
                            'interaction_type': interaction_type,
                            'interaction_time': interaction_time
                        })
        
        return pd.DataFrame(interactions)
    
    def generate_and_save_all(self) -> None:
        print(f"\nğŸ“Š å¼€å§‹ç”Ÿæˆæ•°æ®ï¼ˆ{self.num_users}ç”¨æˆ· + {self.num_items}ç‰©å“ï¼‰")
        users = self.generate_user_data()
        items = self.generate_item_data()
        interactions = self.generate_interaction_data(users, items)
        
        user_path = os.path.join(self.data_dir, 'user_table.csv')
        item_path = os.path.join(self.data_dir, 'item_table.csv')
        interaction_path = os.path.join(self.data_dir, 'interaction_table.csv')
        
        users.to_csv(user_path, index=False)
        items.to_csv(item_path, index=False)
        interactions.to_csv(interaction_path, index=False)
        print(f"âœ… æ•°æ®ç”Ÿæˆå®Œæˆï¼ˆä¿å­˜è·¯å¾„ï¼š{self.data_dir}ï¼‰\n")


# ----------------------
# 2. ä¿®æ­£åçš„ItemCFæ¨èå™¨
# ----------------------
class ItemCFRecommender:
    # ä¿®æ­£1ï¼šè¡¥å……cache_dirå’Œload_from_cacheå‚æ•°ï¼Œè®¾ç½®é»˜è®¤å€¼
    def __init__(self, data_dir: str, cache_dir: Optional[str] = None, load_from_cache: bool = False):
        self.data_dir = data_dir
        self.user_df = None
        self.item_df = None
        self.interaction_df = None
        self.user_item_matrix = None
        self.item_similarity = None
        self.item_id_to_name = None
        
        # ä¿®æ­£2ï¼šæ­£ç¡®åˆå§‹åŒ–ç¼“å­˜ç›®å½•ï¼ˆå…ˆèµ‹å€¼ï¼Œå†åˆ›å»ºç›®å½•ï¼‰
        self.cache_dir = cache_dir if cache_dir else os.path.join(data_dir, 'cache')
        os.makedirs(self.cache_dir, exist_ok=True)  # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
        
        # ä¿®æ­£3ï¼šè°ƒæ•´é¡ºåºï¼šå…ˆåŠ è½½æ•°æ®ï¼Œå†åŠ è½½ç¼“å­˜ï¼ˆç¼“å­˜è¦†ç›–æ•°æ®ä¸­çš„å‚æ•°ï¼‰
        self._load_data()
        self.load_from_cache = load_from_cache
        if self.load_from_cache:
            self.load_params()  # åŠ è½½ç¼“å­˜ï¼ˆè¦†ç›–item_id_to_nameç­‰ï¼‰

    def save_params(self) -> None:
        """æŒä¹…åŒ–ä¿å­˜å…³é”®å‚æ•°"""
        start_time = time.time()
        params_to_save = {
            'user_item_matrix': self.user_item_matrix,
            'item_similarity': self.item_similarity,
            'item_id_to_name': self.item_id_to_name
        }
        
        # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„ç¼“å­˜æ–‡ä»¶ï¼ˆä¾¿äºåŒºåˆ†ç‰ˆæœ¬ï¼‰
        cache_file = os.path.join(
            self.cache_dir, 
            f'itemcf_params_{datetime.now().strftime("%Y%m%d_%H%M%S")}.pkl'
        )
        
        try:
            with open(cache_file, 'wb') as f:
                pickle.dump(params_to_save, f)  # pickleæ”¯æŒdefaultdictç±»å‹
            print(f"ğŸ’¾ å‚æ•°ä¿å­˜å®Œæˆï¼ˆè€—æ—¶ï¼š{time.time() - start_time:.2f}ç§’ï¼‰")
            print(f"ğŸ’¾ ç¼“å­˜è·¯å¾„ï¼š{cache_file}")
        except Exception as e:
            print(f"âŒ å‚æ•°ä¿å­˜å¤±è´¥ï¼š{str(e)}")
    
    def load_params(self) -> bool:
        """åŠ è½½æœ€æ–°ç¼“å­˜å‚æ•°ï¼Œè¿”å›æ˜¯å¦æˆåŠŸ"""
        # ç­›é€‰ç¼“å­˜æ–‡ä»¶ï¼ˆå‰ç¼€+åç¼€åŒ¹é…ï¼‰
        cache_files = [
            f for f in os.listdir(self.cache_dir) 
            if f.startswith('itemcf_params_') and f.endswith('.pkl')
        ]
        if not cache_files:
            print("âš ï¸ æœªæ‰¾åˆ°ç¼“å­˜æ–‡ä»¶")
            return False
        
        # æŒ‰æ—¶é—´æˆ³æ’åºï¼Œå–æœ€æ–°æ–‡ä»¶ï¼ˆæ–‡ä»¶ååç¼€æ˜¯æ—¶é—´ï¼Œé€†åºæ’ï¼‰
        cache_files.sort(reverse=True)
        latest_cache = os.path.join(self.cache_dir, cache_files[0])
        
        try:
            start_time = time.time()
            with open(latest_cache, 'rb') as f:
                params = pickle.load(f)
            
            # æ¢å¤å‚æ•°ï¼ˆåªæ¢å¤å­˜åœ¨çš„é”®ï¼Œé¿å…KeyErrorï¼‰
            self.user_item_matrix = params.get('user_item_matrix')
            self.item_similarity = params.get('item_similarity')
            self.item_id_to_name = params.get('item_id_to_name')
            
            print(f"ğŸ“¥ ç¼“å­˜åŠ è½½å®Œæˆï¼ˆè€—æ—¶ï¼š{time.time() - start_time:.2f}ç§’ï¼‰")
            print(f"ğŸ“¥ åŠ è½½æ–‡ä»¶ï¼š{latest_cache}")
            return True
        except Exception as e:
            print(f"âŒ ç¼“å­˜åŠ è½½å¤±è´¥ï¼š{str(e)}")
            return False

    def _load_data(self) -> None:
        """åŠ è½½ç”¨æˆ·/ç‰©å“/äº¤äº’æ•°æ®ï¼Œç¼ºå¤±åˆ™æŠ¥é”™"""
        start_time = time.time()
        file_paths = {
            'user': os.path.join(self.data_dir, 'user_table.csv'),
            'item': os.path.join(self.data_dir, 'item_table.csv'),
            'interaction': os.path.join(self.data_dir, 'interaction_table.csv')
        }
        
        # æ£€æŸ¥ç¼ºå¤±æ–‡ä»¶
        missing = [k for k, v in file_paths.items() if not os.path.exists(v)]
        if missing:
            raise FileNotFoundError(
                f"âŒ ç¼ºå¤±{', '.join(missing)}æ•°æ®æ–‡ä»¶ï¼\nè¯·å…ˆè¿è¡ŒDataGeneratorç”Ÿæˆæ•°æ®ã€‚"
            )
        
        
        try:
            self.user_df = pd.read_csv(file_paths['user'])
            self.item_df = pd.read_csv(file_paths['item'])
            self.interaction_df = pd.read_csv(file_paths['interaction'])
            # ä»æ•°æ®ä¸­æ„å»ºitem_id_to_nameï¼ˆè‹¥æœªåŠ è½½ç¼“å­˜ï¼Œç”¨è¿™ä¸ªï¼‰
            self.item_id_to_name = dict(zip(self.item_df['item_id'], self.item_df['item_name']))
            

            self.interaction_df["weight"] = self.interaction_df["interaction_type"].apply(self._calculate_interaction_weight)

            print(f"ğŸ“¥ æ•°æ®åŠ è½½å®Œæˆï¼ˆè€—æ—¶ï¼š{time.time() - start_time:.2f}ç§’ï¼‰")
            print(f"ğŸ“¥ æ•°æ®è§„æ¨¡ï¼š{len(self.user_df)}ç”¨æˆ· | {len(self.item_df)}ç‰©å“ | {len(self.interaction_df)}äº¤äº’")
        except Exception as e:
            raise RuntimeError(f"âŒ æ•°æ®åŠ è½½å¤±è´¥ï¼š{str(e)}") from e
    
    def _calculate_interaction_weight(self, interaction_type: str) -> int:
        """è®¡ç®—äº¤äº’æƒé‡ï¼ˆè¦†ç›–æ‰€æœ‰4ç§äº¤äº’ç±»å‹ï¼‰"""
        weight_map = {"ç‚¹å‡»": 1, "æ”¶è—": 2, "åŠ å…¥è´­ç‰©è½¦": 3, "è´­ä¹°": 5}
        return weight_map.get(interaction_type, 0)
    
    def build_user_item_matrix(self) -> None:
        """æ„å»ºç”¨æˆ·-ç‰©å“äº¤äº’çŸ©é˜µï¼ˆå¸¦æƒé‡ï¼‰"""
        if self.interaction_df is None:
            raise ValueError("âŒ æœªåŠ è½½æ•°æ®ï¼Œè¯·å…ˆè°ƒç”¨_load_data()")
        
        start_time = time.time()
        # è®¡ç®—äº¤äº’æƒé‡
        self.interaction_df["weight"] = self.interaction_df["interaction_type"].apply(
            self._calculate_interaction_weight
        )
        
        # æ„å»ºçŸ©é˜µï¼ˆé‡å¤äº¤äº’è‡ªåŠ¨æ±‚å’Œï¼Œç©ºå€¼å¡«0ï¼‰
        self.user_item_matrix = self.interaction_df[["user_id", "item_id", "weight"]].pivot_table(
            index="user_id", columns="item_id", values="weight", aggfunc="sum"
        ).fillna(0)
        
        print(f"\nğŸ”§ çŸ©é˜µæ„å»ºå®Œæˆï¼ˆè€—æ—¶ï¼š{time.time() - start_time:.2f}ç§’ï¼‰")
        print(f"ğŸ”§ çŸ©é˜µå½¢çŠ¶ï¼š{self.user_item_matrix.shape}ï¼ˆè¡Œ=ç”¨æˆ·ï¼Œåˆ—=ç‰©å“ï¼‰")
    
    def calculate_item_similarity(self) -> None:
        """è®¡ç®—ç‰©å“ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆé¿å…é™¤é›¶é”™è¯¯ï¼‰"""
        if self.user_item_matrix is None:
            raise ValueError("âŒ æœªæ„å»ºçŸ©é˜µï¼Œè¯·å…ˆè°ƒç”¨build_user_item_matrix()")
        
        start_time = time.time()
        items = self.user_item_matrix.columns.tolist()
        item_vectors = self.user_item_matrix.values.T  # è½¬ç½®ä¸ºï¼šç‰©å“Ã—ç”¨æˆ·
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        norms = np.linalg.norm(item_vectors, axis=1, keepdims=True)
        norms[norms == 0] = 1e-10  # é¿å…æ— äº¤äº’ç‰©å“çš„æ¨¡é•¿ä¸º0
        normalized_vecs = item_vectors / norms
        sim_matrix = np.dot(normalized_vecs, normalized_vecs.T)
        
        # è½¬æ¢ä¸ºdefaultdictï¼ˆä¾¿äºæŸ¥è¯¢ï¼‰
        self.item_similarity = defaultdict(dict)
        for i, item_i in enumerate(items):
            for j, item_j in enumerate(items):
                if i <= j:  # é¿å…é‡å¤è®¡ç®—ï¼ˆi-jä¸j-iç›¸ä¼¼åº¦ç›¸åŒï¼‰
                    sim = round(sim_matrix[i, j], 4)
                    self.item_similarity[item_i][item_j] = sim
                    self.item_similarity[item_j][item_i] = sim
        
        print(f"ğŸ” ç›¸ä¼¼åº¦è®¡ç®—å®Œæˆï¼ˆè€—æ—¶ï¼š{time.time() - start_time:.2f}ç§’ï¼‰")
        print(f"ğŸ” è®¡ç®—ç‰©å“æ•°ï¼š{len(items)}")
    
    def recommend_items(self, user_id: int, top_n: int = 2, filter_interacted: bool = True) -> List[Tuple[int, float]]:
        """ä¸ºç”¨æˆ·æ¨èTop-Nç‰©å“ï¼ˆè¿‡æ»¤å·²äº¤äº’ï¼‰"""
        if self.item_similarity is None:
            raise ValueError("âŒ æœªè®¡ç®—ç›¸ä¼¼åº¦ï¼Œè¯·å…ˆè°ƒç”¨calculate_item_similarity()")
        
        # è·å–ç”¨æˆ·äº¤äº’å†å²
        user_interacts = self.interaction_df[self.interaction_df["user_id"] == user_id]
        user_items = dict(zip(user_interacts["item_id"], user_interacts["weight"]))
        if not user_items:
            print(f"âš ï¸ ç”¨æˆ·{user_id}æ— äº¤äº’å†å²")
            return []
        
        # è®¡ç®—æ¨èåˆ†æ•°ï¼ˆç›¸ä¼¼åº¦Ã—äº¤äº’æƒé‡ï¼Œç´¯åŠ ï¼‰
        candidate_scores = defaultdict(float)
        for item_i, weight_i in user_items.items():
            for item_j, sim in self.item_similarity.get(item_i, {}).items():
                if filter_interacted and item_j in user_items:
                    continue  # è¿‡æ»¤å·²äº¤äº’ç‰©å“
                candidate_scores[item_j] += sim * weight_i
        
        # æŒ‰åˆ†æ•°é™åºå–Top-N
        return sorted(candidate_scores.items(), key=lambda x: x[1], reverse=True)[:top_n]
    
    def evaluate(self, test_user_ids: Optional[List[int]] = None, top_n: int = 2) -> Dict[str, float]:
        """è¯„ä¼°æ¨èæ•ˆæœï¼ˆå¬å›ç‡/ç²¾ç¡®ç‡ï¼‰ï¼Œä¿®å¤è¾¹ç•Œé”™è¯¯"""
        if self.item_similarity is None:
            raise ValueError("âŒ æœªè®¡ç®—ç›¸ä¼¼åº¦ï¼Œæ— æ³•è¯„ä¼°")
        
        # è·å–æœ‰äº¤äº’çš„ç”¨æˆ·ï¼ˆé¿å…ç©ºæ•°ç»„ï¼‰
        active_users = self.interaction_df["user_id"].unique()
        if len(active_users) == 0:
            print("âš ï¸ æ— äº¤äº’æ•°æ®ï¼Œæ— æ³•è¯„ä¼°")
            return {"æµ‹è¯•ç”¨æˆ·æ•°": 0, "å¹³å‡å¬å›ç‡": 0.0, "å¹³å‡ç²¾ç¡®ç‡": 0.0}
        
        # é€‰æ‹©æµ‹è¯•ç”¨æˆ·ï¼ˆé»˜è®¤20%ï¼Œæœ€å°‘1ä¸ªï¼‰
        if test_user_ids is None:
            sample_size = max(1, min(int(len(active_users) * 0.2), len(active_users)))
            test_user_ids = random.sample(list(active_users), sample_size)
        
        total_recall = 0.0
        total_precision = 0.0
        valid_users = 0
        
        for user_id in test_user_ids:
            # çœŸå®æ­£æ ·æœ¬ï¼šç”¨æˆ·äº¤äº’è¿‡çš„ç‰©å“
            real_items = set(self.interaction_df[self.interaction_df["user_id"] == user_id]["item_id"])
            if len(real_items) < 2:
                continue  # äº¤äº’å¤ªå°‘ï¼Œè·³è¿‡
            
            # æ¨èç‰©å“ï¼šæ¨¡å‹è¾“å‡º
            recommended = set([iid for iid, _ in self.recommend_items(user_id, top_n)])
            if not recommended:
                continue
            
            # å‘½ä¸­ç‰©å“ï¼šæ¨èä¸çœŸå®çš„äº¤é›†
            hits = recommended & real_items
            valid_users += 1
            
            # ç´¯åŠ æŒ‡æ ‡
            total_recall += len(hits) / len(real_items)
            total_precision += len(hits) / len(recommended)
        
        # è®¡ç®—å¹³å‡æŒ‡æ ‡ï¼ˆé¿å…é™¤ä»¥0ï¼‰
        avg_recall = round(total_recall / valid_users, 4) if valid_users else 0.0
        avg_precision = round(total_precision / valid_users, 4) if valid_users else 0.0
        
        return {
            "æµ‹è¯•ç”¨æˆ·æ•°": valid_users,
            "å¹³å‡å¬å›ç‡": avg_recall,
            "å¹³å‡ç²¾ç¡®ç‡": avg_precision
        }
    
    def print_similarity_examples(self, sample_items: Optional[List[int]] = None) -> None:
        """æ‰“å°ç‰©å“ç›¸ä¼¼åº¦ç¤ºä¾‹ï¼ˆéšæœºé€‰2ä¸ªç‰©å“ï¼‰"""
        if self.item_similarity is None:
            raise ValueError("âŒ æœªè®¡ç®—ç›¸ä¼¼åº¦ï¼Œæ— æ³•æ‰“å°ç¤ºä¾‹")
        
        # éšæœºé€‰2ä¸ªç‰©å“ï¼ˆé¿å…ä¼ å…¥ä¸å­˜åœ¨çš„IDï¼‰
        if sample_items is None:
            sample_items = random.sample(list(self.item_similarity.keys()), min(2, len(self.item_similarity)))
        
        print("\nğŸ“‹ ç‰©å“ç›¸ä¼¼åº¦ç¤ºä¾‹ï¼ˆTop3ç›¸ä¼¼ç‰©å“ï¼‰ï¼š")
        for item_i in sample_items:
            item_name_i = self.item_id_to_name.get(item_i, f"ç‰©å“{item_i}")
            # å–é™¤è‡ªèº«å¤–çš„Top3ç›¸ä¼¼ç‰©å“
            similar_items = sorted(
                [(iid, sim) for iid, sim in self.item_similarity[item_i].items() if iid != item_i],
                key=lambda x: x[1], reverse=True
            )[:3]
            
            print(f"\n{item_name_i}ï¼ˆIDï¼š{item_i}ï¼‰çš„ç›¸ä¼¼ç‰©å“ï¼š")
            for item_j, sim in similar_items:
                item_name_j = self.item_id_to_name.get(item_j, f"ç‰©å“{item_j}")
                print(f"  - {item_name_j}ï¼ˆIDï¼š{item_j}ï¼‰ï¼šç›¸ä¼¼åº¦ {sim:.4f}")
    
    def print_recommendations(self, user_id: int, top_n: int = 2) -> None:
        """æ‰“å°ç”¨æˆ·æ¨èç»“æœï¼ˆå«äº¤äº’å†å²ï¼‰"""
        # æ‰“å°äº¤äº’å†å²ï¼ˆå‰5æ¡ï¼‰
        user_interacts = self.interaction_df[self.interaction_df["user_id"] == user_id].head(5)
        print(f"\nğŸ‘¤ ç”¨æˆ·{user_id}çš„äº¤äº’å†å²ï¼ˆå‰5æ¡ï¼‰ï¼š")
        if user_interacts.empty:
            print("  - æ— äº¤äº’å†å²")
        else:
            for _, row in user_interacts.iterrows():
                item_name = self.item_id_to_name.get(row['item_id'], f"ç‰©å“{row['item_id']}")
                weight = self._calculate_interaction_weight(row['interaction_type'])
                print(f"  - {item_name}ï¼ˆIDï¼š{row['item_id']}ï¼‰ï¼š{row['interaction_type']}ï¼ˆæƒé‡ï¼š{weight}ï¼‰")
        
        # æ‰“å°æ¨èç»“æœ
        recommendations = self.recommend_items(user_id, top_n)
        print(f"\nğŸ¯ ä¸ºç”¨æˆ·{user_id}æ¨èTop{top_n}ç‰©å“ï¼š")
        if not recommendations:
            print("  - æ— æ¨èç‰©å“")
        else:
            for i, (item_id, score) in enumerate(recommendations, 1):
                item_name = self.item_id_to_name.get(item_id, f"ç‰©å“{item_id}")
                # å®‰å…¨è·å–ç‰©å“ç±»åˆ«ï¼ˆé¿å…IDä¸å­˜åœ¨ï¼‰
                item_category = self.item_df[self.item_df["item_id"] == item_id]["category"].iloc[0] if \
                    not self.item_df[self.item_df["item_id"] == item_id].empty else "æœªçŸ¥ç±»åˆ«"
                print(f"  {i}. {item_name}ï¼ˆIDï¼š{item_id}ï¼‰")
                print(f"     - æ¨èåˆ†æ•°ï¼š{score:.4f} | ç±»åˆ«ï¼š{item_category}")


# ----------------------
# 3. ä¿®æ­£åçš„ä¸»å‡½æ•°ï¼ˆå«æ•°æ®ç”Ÿæˆï¼‰
# ----------------------
def main():
    # 1. é…ç½®è·¯å¾„
    script_dir = os.path.dirname(os.path.abspath(__file__))
    data_dir = os.path.join(script_dir, 'data')  # æ•°æ®ä¿å­˜ç›®å½•
    cache_dir = os.path.join(script_dir, 'itemcf_cache')  # ç¼“å­˜ä¿å­˜ç›®å½•ï¼ˆç‹¬ç«‹äºæ•°æ®ï¼‰
    
    # 2. æ£€æŸ¥æ•°æ®æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™ç”Ÿæˆ
    data_files = ['user_table.csv', 'item_table.csv', 'interaction_table.csv']
    data_exists = all([os.path.exists(os.path.join(data_dir, f)) for f in data_files])
    
    if not data_exists:
        print("âš ï¸ æœªå‘ç°æ•°æ®æ–‡ä»¶ï¼Œå¼€å§‹ç”Ÿæˆ...")
        generator = DataGenerator(
            data_dir=data_dir,
            num_users=50,
            num_items=30,
            interactions_per_user=(3, 10)
        )
        generator.generate_and_save_all()  # ç”Ÿæˆæ•°æ®
    
    # 3. åˆå§‹åŒ–æ¨èå™¨ï¼ˆå°è¯•åŠ è½½ç¼“å­˜ï¼‰
    try:
        recommender = ItemCFRecommender(
            data_dir=data_dir,
            cache_dir=cache_dir,
            load_from_cache=True  # ä¼˜å…ˆåŠ è½½ç¼“å­˜
        )
        
        # 4. è‹¥ç¼“å­˜ç¼ºå¤±å…³é”®å‚æ•°ï¼Œé‡æ–°è®¡ç®—
        need_recalculate = False
        if recommender.user_item_matrix is None:
            print("\nğŸ”„ ç¼“å­˜ä¸­æ— ç”¨æˆ·-ç‰©å“çŸ©é˜µï¼Œé‡æ–°æ„å»º...")
            recommender.build_user_item_matrix()
            need_recalculate = True
        
        if recommender.item_similarity is None:
            print("ğŸ”„ ç¼“å­˜ä¸­æ— ç‰©å“ç›¸ä¼¼åº¦ï¼Œé‡æ–°è®¡ç®—...")
            recommender.calculate_item_similarity()
            need_recalculate = True
        
        # 5. è‹¥é‡æ–°è®¡ç®—ï¼Œä¿å­˜æ–°å‚æ•°åˆ°ç¼“å­˜
        if need_recalculate:
            recommender.save_params()
        
        # 6. æ‰“å°ç»“æœä¸è¯„ä¼°
        recommender.print_similarity_examples()  # ç›¸ä¼¼åº¦ç¤ºä¾‹
        recommender.print_recommendations(user_id=1003, top_n=3)  # æ¨èç»“æœ
        eval_res = recommender.evaluate(top_n=3)  # è¯„ä¼°
        
        # æ‰“å°è¯„ä¼°ç»“æœ
        print(f"\nğŸ“Š æ¨èç³»ç»Ÿè¯„ä¼°ç»“æœï¼ˆTop3ï¼‰ï¼š")
        for metric, val in eval_res.items():
            print(f"  - {metric}ï¼š{val}")
    
    except Exception as e:
        print(f"\nâŒ ç¨‹åºè¿è¡Œå¤±è´¥ï¼š{str(e)}")


if __name__ == "__main__":
    main()